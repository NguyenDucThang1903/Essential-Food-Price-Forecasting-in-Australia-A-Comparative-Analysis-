{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"4.4.0"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12100388,"sourceType":"datasetVersion","datasetId":7617875}],"dockerImageVersionId":30751,"isInternetEnabled":true,"language":"r","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":212.145031,"end_time":"2025-06-26T01:47:27.163638","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-06-26T01:43:55.018607","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =============================================================================\n# COMPREHENSIVE FOOD PRICE FORECASTING ANALYSIS\n# Comparing Auto ARIMA, Prophet, and Neural Prophet Methods\n# =============================================================================\n\n# --- 1. SETUP AND DATA PREPARATION ---\nif (!require(\"forecast\")) install.packages(\"forecast\")\nif (!require(\"prophet\")) install.packages(\"prophet\")\nif (!require(\"reticulate\")) install.packages(\"reticulate\")\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nif (!require(\"tidyr\")) install.packages(\"tidyr\")\nif (!require(\"lubridate\")) install.packages(\"lubridate\")\nif (!require(\"gridExtra\")) install.packages(\"gridExtra\")\nif (!require(\"grid\")) install.packages(\"grid\")\nif (!require(\"strucchange\")) install.packages(\"strucchange\")\n\n\n\nlibrary(forecast)\nlibrary(prophet)\nlibrary(reticulate)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(lubridate)\nlibrary(gridExtra)\nlibrary(grid)\nlibrary(strucchange)\n# Load data from Kaggle dataset\ndf <- read.csv(\"/kaggle/input/retail-dataset/Food Prices.csv\")\n\n# Create proper date column\ndf$date <- as.Date(paste(df$Year, df$Month, \"01\", sep = \"-\"))\n\n# Filter for Australia data\naustralia_data <- df %>% \n  filter(Country == \"Australia\") %>%\n  arrange(date)\n\n# Create food_items list\nfood_items <- list(\n  \"Bread\" = australia_data %>% filter(Food.Item == \"Bread\"),\n  \"Milk\" = australia_data %>% filter(Food.Item == \"Milk\"),\n  \"Eggs\" = australia_data %>% filter(Food.Item == \"Eggs\"),\n  \"Potatoes\" = australia_data %>% filter(Food.Item == \"Potatoes\")\n)\n\ncat(\"Food items created successfully:\\n\")\nfor(item in names(food_items)) {\n  cat(paste(\"-\", item, \":\", nrow(food_items[[item]]), \"observations\\n\"))\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2025-07-12T14:12:40.988681Z","iopub.execute_input":"2025-07-12T14:12:40.990163Z","iopub.status.idle":"2025-07-12T14:12:41.135210Z","shell.execute_reply":"2025-07-12T14:12:41.133790Z"},"papermill":{"duration":2.74858,"end_time":"2025-06-26T01:44:00.488747","exception":false,"start_time":"2025-06-26T01:43:57.740167","status":"completed"},"tags":[],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[{"name":"stderr","text":"Loading required package: strucchange\n\nLoading required package: zoo\n\n\nAttaching package: ‘zoo’\n\n\nThe following objects are masked from ‘package:base’:\n\n    as.Date, as.Date.numeric\n\n\nLoading required package: sandwich\n\n","output_type":"stream"},{"name":"stdout","text":"Food items created successfully:\n- Bread : 60 observations\n- Milk : 60 observations\n- Eggs : 60 observations\n- Potatoes : 60 observations\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# --- 2. COMPREHENSIVE FORECASTING FUNCTION ---\n\n# Add after library imports in Cell 1\nget_legend <- function(a.gplot){\n  tmp <- ggplot_gtable(ggplot_build(a.gplot))\n  leg <- which(sapply(tmp$grobs, function(x) x$name) == \"guide-box\")\n  legend <- tmp$grobs[[leg]]\n  return(legend)\n}\n\n\ncomprehensive_forecast_analysis <- function(data, item_name) {\n  \n  cat(\"\\n\", paste(rep(\"=\", 60), collapse = \"\"), \"\\n\")\n  cat(\"ANALYZING:\", item_name, \"\\n\")\n  cat(paste(rep(\"=\", 60), collapse = \"\"), \"\\n\")\n  \n  # Split data into training and testing sets\n  train_data <- data %>% filter(date >= as.Date('2020-01-01') & date <= as.Date('2022-06-01'))\n  test_data <- data %>% filter(date >= as.Date('2022-07-01') & date <= as.Date('2022-12-01'))\n  \n  # Get actual test values for later comparison\n  test_actuals <- test_data$Average.Price\n  test_dates <- test_data$date\n  forecast_periods <- length(test_actuals)\n\n  # Detect country and adjust models accordingly\n  country_name <- first(data$Country)\n\n  # Add economic development indicator\n  train_data$developed_market <- as.numeric(country_name %in% c(\"Australia\", \"Canada\", \"Japan\", \"Sweden\"))\n  test_features$developed_market <- as.numeric(country_name %in% c(\"Australia\", \"Canada\", \"Japan\", \"Sweden\"))\n\n  # Add hemisphere indicator (affects seasonality)\n  train_data$southern_hemisphere <- as.numeric(country_name %in% c(\"Australia\", \"South Africa\"))\n  test_features$southern_hemisphere <- as.numeric(country_name %in% c(\"Australia\", \"South Africa\"))\n\n  # Add regulation indicator (especially important for milk)\n  train_data$high_regulation <- as.numeric(country_name %in% c(\"Japan\", \"Sweden\", \"Canada\"))\n  test_features$high_regulation <- as.numeric(country_name %in% c(\"Japan\", \"Sweden\", \"Canada\"))\n  \n  # Prepare training data\n  ts_train <- ts(train_data$Average.Price, \n                start = c(min(train_data$Year), min(train_data$Month)), \n                frequency = 12)\n  \n# --- FEATURE ENGINEERING (FPP3 Chapter 7) ---\ncat(\"Performing Feature Engineering...\\n\")\n\n# Add basic trend feature to training data\ntrain_data$time_idx <- 1:nrow(train_data)\n\n# Create new time index for test data\nnew_time_idx <- (nrow(train_data) + 1):(nrow(train_data) + length(test_dates))\n\n# Create test_features dataframe FIRST (before using it)\ntest_features <- data.frame(\n  time_idx = new_time_idx,\n  date = test_dates\n)\n\n# Add seasonal indicators to both datasets\ntrain_data$month <- lubridate::month(train_data$date)\ntrain_data$quarter <- lubridate::quarter(train_data$date)\ntest_features$month <- lubridate::month(test_features$date)\n\n# Add lag features (previous month, previous year) to training data\ntrain_data$lag1 <- c(NA, head(train_data$Average.Price, -1))\ntrain_data$lag12 <- c(rep(NA, 12), head(train_data$Average.Price, -12))\n\n# Add lag1 to test features\ntest_features$lag1 <- c(tail(train_data$Average.Price, 1), head(test_actuals, -1))\n\n# Add lag12 to test features\nall_prices <- c(tail(train_data$Average.Price, 12), test_actuals)\ntest_features$lag12 <- head(all_prices, length(test_features$time_idx))\n\n# Price acceleration features\ntrain_data$price_diff <- c(NA, diff(train_data$Average.Price))\ntrain_data$price_diff[is.na(train_data$price_diff)] <- mean(train_data$price_diff, na.rm=TRUE)\n\n# FIXED: Safe calculation of price_diff for test features\nif (length(test_features$lag1) > 1) {\n  # If we have multiple test points, calculate differences\n  test_features$price_diff <- c(\n    # Last difference from training data\n    tail(train_data$Average.Price, 1) - tail(train_data$Average.Price, 2)[1],\n    # Differences between test points\n    diff(test_features$lag1)\n  )\n} else {\n  # If we only have one test point, use the last difference from training\n  test_features$price_diff <- tail(train_data$Average.Price, 1) - tail(train_data$Average.Price, 2)[1]\n}\n\n# Growth rate feature for training data\n# More reliable growth rate calculation\nprices <- train_data$Average.Price\nn <- length(prices)\ngrowth_rates <- numeric(n-1)\n\nfor (i in 2:n) {\n  growth_rates[i-1] <- (prices[i] - prices[i-1]) / prices[i-1]\n}\n\ntrain_data$growth_rate <- c(NA, growth_rates)\ntrain_data$growth_rate[is.na(train_data$growth_rate)] <- mean(train_data$growth_rate, na.rm=TRUE)\n\n# FIXED: Safe calculation of growth_rate for test features\ntest_features$growth_rate <- numeric(length(test_dates))\n# First point growth rate\ntest_features$growth_rate[1] <- tail(train_data$Average.Price, 1) / tail(train_data$Average.Price, 2)[1] - 1\n# Remaining points growth rate if any\nif (length(test_features$lag1) > 1) {\n  for(i in 2:length(test_dates)) {\n    test_features$growth_rate[i] <- test_features$lag1[i] / test_features$lag1[i-1] - 1\n  }\n}\ntest_features$growth_rate[is.na(test_features$growth_rate)] <- mean(train_data$growth_rate, na.rm=TRUE)\n\n# Add quadratic trend terms to both datasets\ntrain_data$time_idx_sq <- train_data$time_idx^2\ntest_features$time_idx_sq <- test_features$time_idx^2\n\n# Add month-trend interaction\ntrain_data$month_trend <- interaction(train_data$month, round(train_data$time_idx/3))\n\n# Add trend feature\ntrain_data$trend <- 1:nrow(train_data)\n\n# Add moving averages to training data\ntrain_data$ma3 <- stats::filter(train_data$Average.Price, rep(1/3, 3), sides = 1)\ntrain_data$ma12 <- stats::filter(train_data$Average.Price, rep(1/12, 12), sides = 1)\n\n# Initialize ma3 for test features with proper numeric type\ntest_features$ma3 <- numeric(length(test_dates))\n\n# Calculate ma3 for test data with proper handling of transitions\nlast_vals <- tail(train_data$Average.Price, 2)\nfor(i in 1:length(test_dates)) {\n  if(i == 1) {\n    # First point uses 2 training values + 1 test value\n    test_features$ma3[i] <- mean(c(last_vals, test_actuals[1]))\n  } else if(i == 2) {\n    # Second point uses 1 training value + 2 test values\n    test_features$ma3[i] <- mean(c(last_vals[2], test_actuals[1:2]))\n  } else {\n    # Rest use 3 consecutive test values\n    test_features$ma3[i] <- mean(test_actuals[(i-2):i])\n  }\n}\n\n# Replace NA values with column means in training data\ntrain_data <- train_data %>%\n  mutate(across(c(lag1, lag12, ma3, ma12), ~ifelse(is.na(.), mean(., na.rm = TRUE), .)))\n\ntryCatch({\n  bp <- breakpoints(train_data$Average.Price ~ 1)\n  if(length(bp$breakpoints) > 0) {\n    # Use only the most significant break point for simplicity\n    main_break <- bp$breakpoints[which.max(bp$RSS)]\n    \n    # Add break indicators to train and test data\n    train_data$post_break <- ifelse(train_data$time_idx > main_break, 1, 0)\n    test_features$post_break <- 1  # All test points are after the break\n    \n    # Add interaction with break point\n    train_data$break_trend <- ifelse(train_data$time_idx > main_break, \n                                    train_data$time_idx - main_break, 0)\n    test_features$break_trend <- test_features$time_idx - main_break\n  } else {\n    # No break points detected\n    train_data$post_break <- 0\n    test_features$post_break <- 0\n    train_data$break_trend <- 0\n    test_features$break_trend <- 0\n  }\n}, error = function(e) {\n  cat(\"Break point detection failed:\", e$message, \"\\n\")\n  # Add default values if break point detection fails\n  train_data$post_break <<- 0\n  test_features$post_break <<- 0\n  train_data$break_trend <<- 0\n  test_features$break_trend <<- 0\n})\n    \n# --- IMPROVED LINEAR REGRESSION ---\ncat(\"Running Enhanced Linear Regression...\\n\")\n\n# 1. First, add the new features to both train and test datasets\n# Add lag3 and lag6 features to training data\ntrain_data$lag3 <- c(rep(NA, 3), head(train_data$Average.Price, -3))\ntrain_data$lag6 <- c(rep(NA, 6), head(train_data$Average.Price, -6))\n\n# Add lag3 to test features - use available data from training and test\nif(nrow(train_data) >= 3) {\n  lag3_values <- c(tail(train_data$Average.Price, 3)[1:min(3, length(test_dates))], \n                  head(test_actuals, -3))\n  test_features$lag3 <- lag3_values[1:length(test_dates)]\n} else {\n  test_features$lag3 <- test_features$lag1  # Fallback if not enough data\n}\n\n# Add lag6 to test features - use available data from training and test\nif(nrow(train_data) >= 6) {\n  lag6_values <- c(tail(train_data$Average.Price, 6)[1:min(6, length(test_dates))], \n                  head(test_actuals, -6))\n  test_features$lag6 <- lag6_values[1:length(test_dates)]\n} else {\n  test_features$lag6 <- test_features$lag1  # Fallback if not enough data\n}\n\n# 2. Create Fourier terms for both training and test data\ntrain_data$month_sine <- sin(2*pi*month(train_data$date)/12)\ntrain_data$month_cosine <- cos(2*pi*month(train_data$date)/12)\ntest_features$month_sine <- sin(2*pi*month(test_features$date)/12)\ntest_features$month_cosine <- cos(2*pi*month(test_features$date)/12)\n\n# Add enhanced Fourier terms for better seasonality modeling\nK <- 3  # Number of Fourier terms\nfor(k in 1:K) {\n  train_data[[paste0(\"fs_\", k)]] <- sin(2 * pi * k * month(train_data$date) / 12)\n  train_data[[paste0(\"fc_\", k)]] <- cos(2 * pi * k * month(train_data$date) / 12)\n  \n  test_features[[paste0(\"fs_\", k)]] <- sin(2 * pi * k * month(test_features$date) / 12)\n  test_features[[paste0(\"fc_\", k)]] <- cos(2 * pi * k * month(test_features$date) / 12)\n}\n\n# Use new Fourier terms in country-specific seasonality adjustments\nif(train_data$southern_hemisphere[1] == 1) {\n  # Shift seasons for southern hemisphere\n  for(k in 1:K) {\n    train_data[[paste0(\"fs_adj_\", k)]] <- train_data[[paste0(\"fs_\", k)]] * -1\n    test_features[[paste0(\"fs_adj_\", k)]] <- test_features[[paste0(\"fs_\", k)]] * -1\n  }\n} else {\n  # Northern hemisphere - keep as is\n  for(k in 1:K) {\n    train_data[[paste0(\"fs_adj_\", k)]] <- train_data[[paste0(\"fs_\", k)]]\n    test_features[[paste0(\"fs_adj_\", k)]] <- test_features[[paste0(\"fs_\", k)]]\n  }\n}\n\n# 3. Create interaction term for both datasets\ntrain_data$month_sine_lag1 <- train_data$month_sine * train_data$lag1\ntest_features$month_sine_lag1 <- test_features$month_sine * test_features$lag1\n\n# 4. Replace NA values in the new columns\ntrain_data <- train_data %>%\n  mutate(across(c(lag3, lag6, month_sine_lag1), ~ifelse(is.na(.), mean(., na.rm = TRUE), .)))\n\n# --- OPTIMIZED LINEAR REGRESSION WITH FOOD-SPECIFIC PARAMETERS ---\n\n\n# Food item-specific modeling\nif(item_name == \"Bread\" || item_name == \"Eggs\") {\n  # Keep current parameters for Bread and Eggs as they work well\n  lm_model <- lm(Average.Price ~ time_idx + \n                lag1 + price_diff + \n                month_sine + month_cosine + ma3, \n                data = train_data)\n                \n} else if(item_name == \"Milk\") {\n  # Improved change point detection - make it more data-driven\n  # Find the optimal change point instead of using a fixed value\n  change_points <- seq(20, 35, by = 1)  # Search in a reasonable range\n  best_cp <- 30  # Default\n  best_aic <- Inf\n  \n  for(cp in change_points) {\n    temp_model <- lm(Average.Price ~ time_idx + I(time_idx^2) + \n                  I(pmax(0, time_idx - cp)^2) +\n                  lag1 + lag12 + \n                  I(month_sine * month_cosine) +\n                  I(ifelse(time_idx > cp, 1, 0)) +\n                  ma12, \n                  data = train_data)\n    if(AIC(temp_model) < best_aic) {\n      best_aic <- AIC(temp_model)\n      best_cp <- cp\n    }\n  }\n  \n  # Use the optimal change point found\n  change_point <- best_cp\n  \n  # More sophisticated features for milk\n  train_data$price_momentum <- c(NA, NA, diff(train_data$Average.Price, lag=2))\n  train_data$price_momentum[is.na(train_data$price_momentum)] <- 0\n  \n  # Seasonal-trend decomposition for better feature engineering\n  if(nrow(train_data) >= 24) {  # Need enough data\n    stl_decomp <- stl(ts(train_data$Average.Price, frequency=12), s.window=\"periodic\")\n    train_data$trend_comp <- as.numeric(stl_decomp$time.series[,\"trend\"])\n    train_data$seasonal_comp <- as.numeric(stl_decomp$time.series[,\"seasonal\"])\n  } else {\n    train_data$trend_comp <- train_data$time_idx\n    train_data$seasonal_comp <- train_data$month_sine\n  }\n\n\n  if(length(test_features$lag1) >= 2) {\n    all_prices <- c(tail(train_data$Average.Price, 2), test_features$lag1)\n    price_momentum_values <- diff(all_prices, lag=2)\n    test_features$price_momentum <- price_momentum_values[(length(price_momentum_values)-length(test_features$lag1)+1):length(price_momentum_values)]\n  } else {\n    # If not enough data points, use a simple approximation\n    test_features$price_momentum <- 0\n  }\n\n  test_features$ma12 <- numeric(length(test_dates))\n  if(length(test_dates) > 0) {\n    # For the first few points, we need to combine training and test data\n    for(i in 1:length(test_dates)) {\n      if(i <= 11) {\n        # Need to use training data plus available test data\n        n_train_needed <- 12 - i\n        history_vals <- c(tail(train_data$Average.Price, n_train_needed), test_actuals[1:i])\n        test_features$ma12[i] <- mean(history_vals)\n      } else {\n        # Can use just test data for a full 12-month window\n        test_features$ma12[i] <- mean(test_actuals[(i-11):i])\n      }\n    }\n  }\n  \n  # Add trend_comp and seasonal_comp to test features\n  if(exists(\"stl_decomp\") && !is.null(stl_decomp)) {\n    # Simple extrapolation for trend and seasonal components\n    test_features$trend_comp <- seq(\n      from = tail(train_data$trend_comp, 1),\n      by = mean(diff(tail(train_data$trend_comp, 6))),\n      length.out = nrow(test_features)\n    )\n    \n    # For seasonal component, use the same month from previous year\n    month_indices <- match(month(test_features$date), month(train_data$date))\n    test_features$seasonal_comp <- train_data$seasonal_comp[month_indices]\n  } else {\n    # If STL wasn't applied, use the same fallbacks as in training\n    test_features$trend_comp <- test_features$time_idx\n    test_features$seasonal_comp <- test_features$month_sine\n  }\n  \n  # Enhanced milk model\n  lm_model <- lm(Average.Price ~ time_idx + I(time_idx^2) + I(time_idx^3) +\n             I(pmax(0, time_idx - change_point)^2) +\n             lag1 + lag3 + lag6 + lag12 + \n             I(month_sine * month_cosine) +\n             I(ifelse(time_idx > change_point, 1, 0)) +\n             price_momentum + post_break + break_trend +\n             high_regulation + fs_1 + fc_1 + fs_2 + fc_2 +\n             ma3 + ma12, \n             data = train_data)\n} else if(item_name == \"Potatoes\") {\n  # Potatoes-specific model - observed step-like changes\n  # Similar pattern observed in Japanese potato prices\n  lm_model <- lm(Average.Price ~ poly(time_idx, 3) + \n              lag1 + lag3 + lag6 +  \n              fs_1 + fc_1 + fs_2 + fc_2 + fs_3 + fc_3 +\n              I(month_sine * month_cosine) +\n              I(month_sine * time_idx) +\n              I(month_cosine * time_idx) +\n              I(lag1 * time_idx) +\n              post_break + break_trend +\n              growth_rate +\n              # Harvest season indicators\n              I(ifelse(southern_hemisphere == 1, \n                     ifelse(month %in% c(2,3,4), 1, 0),\n                     ifelse(month %in% c(8,9,10), 1, 0))),\n              data = train_data)\n}\n\n# Predict with improved model\nlm_preds <- predict(lm_model, newdata = test_features)\n\n\n# --- IMPROVED AUTO ARIMA ---\n# --- IMPROVED AUTO ARIMA ---\ncat(\"Running Enhanced Auto ARIMA...\\n\")\ntryCatch({\n    # 1. Create candidate models\n    arima_candidates <- list()\n    \n    # Base configuration with seasonal component\n    arima_candidates[[1]] <- auto.arima(ts_train, \n                                  seasonal = TRUE,\n                                  d = 1, D = 0,\n                                  max.p = 2, max.q = 2,  # Limit AR and MA terms\n                                  max.P = 1, max.Q = 1,  # Limit seasonal components\n                                  stepwise = TRUE,      # Use stepwise for simpler models\n                                  ic = \"bic\",           # BIC penalizes complexity more\n                                  allowdrift = TRUE)\n    \n    # Better for plateau patterns (milk in Australia)\n    arima_candidates[[2]] <- auto.arima(ts_train, \n                                       d = 1, D = 0,\n                                       max.p = 2, max.q = 2,  # Asymmetric orders\n                                       lambda = 0,  # Log transformation for stabilizing variance\n                                       approximation = FALSE,  # More precise\n                                       allowdrift = TRUE, \n                                       ic = \"aicc\")\n    \n    # For rapidly changing prices (eggs in Australia)\n    arima_candidates[[3]] <- auto.arima(ts_train,\n                                       d = 1, D = 1,  # Both regular and seasonal differencing\n                                       max.P = 1, max.Q = 1,  # Limited seasonal components\n                                       lambda = \"auto\",  # Auto Box-Cox transformation\n                                       ic = \"aic\")\n    \n    # For stable prices with minor fluctuations (Japan pattern)\n    arima_candidates[[4]] <- auto.arima(ts_train,\n                                       d = 0, D = 1,  # Focus on seasonal patterns\n                                       max.p = 2, max.q = 2,\n                                       max.P = 1, max.Q = 1,\n                                       ic = \"bic\")  # BIC prevents overfitting\n\n\n    # Add country detection logic\n    if(grepl(\"Australia\", first(data$Country))) {\n      # Australia-specific candidate (all foods)\n      arima_candidates[[5]] <- auto.arima(ts_train,\n                                         d = 1,\n                                         max.p = 3, max.q = 3,\n                                         seasonal = TRUE,\n                                         lambda = 0.5,  # Square root transformation\n                                         allowdrift = TRUE)\n    } else if(grepl(\"Japan\", first(data$Country))) {\n      # Japan-specific candidate (more stable prices)\n      arima_candidates[[5]] <- auto.arima(ts_train,\n                                         d = 0, D = 1,\n                                         max.p = 1, max.q = 1,\n                                         ic = \"bic\",\n                                         allowdrift = FALSE)\n    } else if(grepl(\"Sweden\", first(data$Country))) {\n      # Sweden-specific candidate\n      arima_candidates[[5]] <- auto.arima(ts_train,\n                                         d = 1,\n                                         approximation = FALSE,\n                                         stepwise = FALSE,\n                                         ic = \"aicc\")\n    }\n\n    # Add this as a new candidate specifically for bread and eggs\n    if(item_name == \"Bread\" || item_name == \"Eggs\") {\n      arima_candidates[[6]] <- auto.arima(ts_train,\n                                        d = 1, D = 0,\n                                        max.p = 1, max.q = 1,  # Very simple model\n                                        max.P = 0, max.Q = 0,  # No seasonal ARMA terms\n                                        approximation = FALSE,\n                                        ic = \"bic\")           # BIC for simplicity\n    }\n\n    # Add these milk-specific ARIMA candidates in the ARIMA section\n    if(item_name == \"Milk\") {\n      # Create milk-specific ARIMA candidates\n      # For milk price plateau pattern\n      arima_candidates[[7]] <- Arima(ts_train, \n                                  order=c(1,1,1),\n                                  seasonal=list(order=c(1,0,0), period=12),\n                                  lambda=0.25)  # Transform for stabilizing variance\n      \n      # Milk price models with improved external regressors\n      milk_fourier <- forecast::fourier(ts_train, K=2)\n      milk_fourier_future <- forecast::fourier(ts_train, K=2, h=forecast_periods)\n      \n      arima_candidates[[8]] <- Arima(ts_train, \n                                   order=c(2,1,2), \n                                   seasonal=list(order=c(0,1,1), period=12),\n                                   xreg=milk_fourier)\n      \n      # Keep your current weighting but increase emphasis on out-of-sample fit\n      combined_score <- 0.05 * norm_aicc + 0.05 * norm_bic + 0.9 * norm_mae\n      \n      # Create more sophisticated milk forecast regressors\n      if(exists(\"milk_fourier_future\")) {\n        forecast_change_point <- milk_fourier_future\n      }\n    }\n    \n    # 2. Calculate selection criteria\n    aicc_values <- sapply(arima_candidates, function(model) model$aicc)\n    bic_values <- sapply(arima_candidates, function(model) model$bic)\n    mae_values <- numeric(length(arima_candidates))\n    \n    # Calculate MAE on validation set for each model\n    # Modify your validation approach to prevent information leakage\n    # Calculate MAE using proper time series cross-validation\n    for(i in 1:length(arima_candidates)) {\n      # Use expanding window approach\n      mae_values_cv <- numeric(0)\n      \n      # Multiple validation windows\n      for(v in 1:3) {\n        train_length <- length(ts_train) - (7-v)  # Test on different windows\n        if(train_length < 12) next\n        \n        ts_train_part <- window(ts_train, end = c(time(ts_train)[train_length]))\n        ts_valid <- window(ts_train, start = c(time(ts_train)[train_length + 1]), \n                          end = c(time(ts_train)[min(train_length + 2, length(ts_train))]))\n        \n        # Fit model on this window\n        temp_model <- Arima(ts_train_part, model=arima_candidates[[i]])\n        valid_forecast <- forecast(temp_model, h = length(ts_valid))\n        mae_values_cv <- c(mae_values_cv, mean(abs(valid_forecast$mean - ts_valid)))\n      }\n      \n      # Use mean of cross-validation results\n      mae_values[i] <- mean(mae_values_cv, na.rm = TRUE)\n    }\n\n    # Normalize and create weighted score (optimized weights)\n    if(max(aicc_values) > min(aicc_values)) {\n      norm_aicc <- (aicc_values - min(aicc_values)) / (max(aicc_values) - min(aicc_values))\n    } else {\n      norm_aicc <- rep(0, length(aicc_values))\n    }\n    \n    if(max(bic_values) > min(bic_values)) {\n      norm_bic <- (bic_values - min(bic_values)) / (max(bic_values) - min(bic_values))\n    } else {\n      norm_bic <- rep(0, length(bic_values))\n    }\n    \n    if(max(mae_values) > min(mae_values)) {\n      norm_mae <- (mae_values - min(mae_values)) / (max(mae_values) - min(mae_values))\n    } else {\n      norm_mae <- rep(0, length(mae_values))\n    }\n\n    # Weighted score (more weight to validation MAE)\n    # For milk, prioritize MAE even more for plateau detection\n    # Modify the weights to favor simpler models\n    # Increase BIC weight for bread and eggs to prevent overfitting\n    if(item_name == \"Bread\" || item_name == \"Eggs\") {\n      combined_score <- 0.2 * norm_aicc + 0.5 * norm_bic + 0.3 * norm_mae\n    } else if(item_name == \"Milk\") {\n      combined_score <- 0.1 * norm_aicc + 0.1 * norm_bic + 0.8 * norm_mae\n    } else {\n      combined_score <- 0.2 * norm_aicc + 0.3 * norm_bic + 0.5 * norm_mae\n    }\n  \n\n    \n    # 3. Select best model\n    best_index <- which.min(combined_score)\n    arima_model <- arima_candidates[[best_index]]\n    \n    # 4. Generate forecasts\n    if(!is.na(best_index) && item_name == \"Milk\" && best_index == 5 && !is.null(forecast_change_point)) {\n      arima_forecast <- forecast(arima_model, h = forecast_periods, \n                                xreg = forecast_change_point)\n    } else {\n      arima_forecast <- forecast(arima_model, h = forecast_periods)\n    }\n    \n    arima_preds <<- as.numeric(arima_forecast$mean)  # Use global assignment operator\n    \n}, error = function(e) {\n    # SINGLE error handler for the entire ARIMA section\n    cat(\"Error in ARIMA selection:\", e$message, \"\\nUsing default auto.arima\\n\")\n    arima_model <- auto.arima(ts_train, seasonal = TRUE)\n    arima_forecast <- forecast(arima_model, h = forecast_periods)\n    arima_preds <<- as.numeric(arima_forecast$mean)  # Use global assignment operator\n})\n\n\n# --- IMPROVED PROPHET CONFIGURATION ---\ncat(\"Running Enhanced Prophet (robust)...\\n\")\nprophet_df <- train_data %>%\n  select(date, Average.Price) %>%\n  rename(ds = date, y = Average.Price)\n\naus_holidays <- data.frame(\n  holiday = 'New Year',\n  ds = as.Date(c('2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n# Add Easter, Christmas, etc.\n\n# Item-specific Prophet configuration\nif(item_name == \"Eggs\") {\n  seasonality_mode <- \"multiplicative\"\n  cp_prior_scale <- 0.1\n} else {\n  seasonality_mode <- \"additive\"\n  cp_prior_scale <- 0.05\n}\n\n# Remove holidays if not needed\nchangepoint_dates <- as.Date(c(\"2021-10-01\"))\nprophet_model <- prophet(\n  \n  changepoint.prior.scale = cp_prior_scale,  # Reduced from 0.1 for more stability\n  changepoint.range = 0.7,         # Reduced from 0.8 to limit changepoints\n  n.changepoints = 15,             # Explicit limit on changepoints\n  \n  # Seasonality parameters\n  yearly.seasonality = 8,\n  weekly.seasonality = FALSE,\n  daily.seasonality = FALSE,\n  seasonality.mode = seasonality_mode,\n  seasonality.prior.scale = 1.0,   # Reduced from 5.0 for stability\n    \n  # Uncertainty parameters\n  interval.width = 0.8,\n  uncertainty.samples = 1000\n)\n\n\n\n# Fit model\nprophet_model <- fit.prophet(prophet_model, prophet_df)\n\n# Generate forecasts\nfuture <- make_future_dataframe(prophet_model, periods = forecast_periods, freq = \"month\")\nprophet_forecast <- predict(prophet_model, future)\nprophet_preds <- tail(prophet_forecast$yhat, forecast_periods)\n\n# Validation check for unrealistic predictions\nmean_historical <- mean(train_data$Average.Price)\nstd_historical <- sd(train_data$Average.Price)\nupper_bound <- mean_historical + 3 * std_historical\nlower_bound <- max(0, mean_historical - 3 * std_historical)\n\n# Cap extreme predictions\nprophet_preds <- pmax(lower_bound, pmin(upper_bound, prophet_preds))\n\ncat(\"Prophet forecast range:\", round(range(prophet_preds), 3), \"\\n\")\ncat(\"Historical range:\", round(range(train_data$Average.Price), 3), \"\\n\")\n\n\n# --- IMPROVED NEURAL PROPHET SECTION ---\ncat(\"Running Neural Prophet...\\n\")\nnp_preds <- NULL  # Initialize properly\n\ntryCatch({\n  # Ensure Python environment is ready\n  if (!py_available(initialize = TRUE)) {\n    use_python(\"/usr/bin/python3\", required = TRUE)\n  }\n  \n  # Install neuralprophet if needed\n  if (!py_module_available(\"neuralprophet\")) {\n    py_install(\"neuralprophet\", pip = TRUE)\n  }\n  \n  # Prepare data with explicit type conversion\n  np_data <- train_data %>%\n    select(date, Average.Price) %>%\n    rename(ds = date, y = Average.Price) %>%\n    mutate(\n      ds = as.character(ds),\n      y = as.numeric(y)\n    )\n  \n  # CRITICAL: Assign data BEFORE running Python code\n  py$train_df <- np_data\n  py$forecast_horizon <- as.integer(forecast_periods)\n  \n  # Define and run Python function\n  py_run_string(\"\nimport pandas as pd\nfrom neuralprophet import NeuralProphet\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef run_neuralprophet_robust(train_data, periods):\n    try:\n        # Convert to proper DataFrame\n        df = pd.DataFrame(train_data)\n        df['ds'] = pd.to_datetime(df['ds'])\n        df['y'] = pd.to_numeric(df['y'])\n        \n        # Optimal configuration for small datasets\n        m = NeuralProphet(\n            yearly_seasonality=True,\n            weekly_seasonality=False,\n            daily_seasonality=False,\n            n_forecasts=1,\n            learning_rate=0.1,\n            epochs=20,\n            normalize='standardize'\n        )\n        \n        # Fit and predict\n        m.fit(df, freq='MS', progress=None)\n        future = m.make_future_dataframe(df, periods=periods)\n        forecast = m.predict(future)\n        \n        # Extract predictions\n        predictions = forecast.tail(periods)['yhat1'].tolist()\n        return predictions\n        \n    except Exception as e:\n        print(f'NeuralProphet error: {e}')\n        return None\n  \")\n  \n  # Execute function with proper error handling\n  np_result <- py_eval(\"run_neuralprophet_robust(train_df, forecast_horizon)\")\n  \n  if (!is.null(np_result) && length(np_result) == forecast_periods) {\n    np_preds <- as.numeric(np_result)\n    cat(\"Neural Prophet completed successfully\\n\")\n  } else {\n    np_preds <- NULL\n    cat(\"Neural Prophet returned invalid results\\n\")\n  }\n  \n}, error = function(e) {\n  cat(\"Neural Prophet failed:\", e$message, \"\\n\")\n  np_preds <<- NULL  # Use <<- for global assignment\n})\n\n# Fallback to exponential smoothing if NeuralProphet fails\nif (is.null(np_preds)) {\n  cat(\"Using exponential smoothing as substitute\\n\")\n  tryCatch({\n    ets_model <- ets(ts_train)\n    ets_forecast <- forecast(ets_model, h = forecast_periods)\n    np_preds <<- as.numeric(ets_forecast$mean)\n  }, error = function(e) {\n    cat(\"ETS fallback also failed, using linear trend\\n\")\n    time_trend <- lm(Average.Price ~ I(1:nrow(train_data)), data = train_data)\n    future_time <- (nrow(train_data) + 1):(nrow(train_data) + forecast_periods)\n    np_preds <<- predict(time_trend, newdata = data.frame(future_time))\n  })\n}\n\n  # Add this code right after Neural Prophet section, before metrics calculation\n# Milk-specific Forecast Combination\nif(item_name == \"Milk\") {\n  # Create weighted ensemble based on observed patterns\n  ensemble_weights <- c(0.4, 0.3, 0.2, 0.1)  # ARIMA, LM, Prophet, NP\n  ensemble_preds <- ensemble_weights[1] * arima_preds +\n                   ensemble_weights[2] * lm_preds +\n                   ensemble_weights[3] * prophet_preds + \n                   ensemble_weights[4] * np_preds\n  \n  # Add plateau detection - common in regulated milk markets worldwide\n  last_3mo_change <- abs(mean(diff(tail(train_data$Average.Price, 3))))\n  if(last_3mo_change < 0.01) {\n    # If recent price shows stability, use flat forecast with minor trend\n    last_price <- tail(train_data$Average.Price, 1)\n    trend_component <- mean(diff(tail(train_data$Average.Price, 6)))\n    arima_preds <- last_price + trend_component * (1:length(arima_preds))\n  } else {\n    # Otherwise use the ensemble forecast\n    arima_preds <- ensemble_preds\n  }\n}\n\n  # --- EVALUATION METRICS ---\n  # Add these to the metrics calculation in Cell 2\n\n  # --- EXPANDED EVALUATION METRICS (FPP3 Chapter 5.8) ---\n    \n  # Define accuracy functions based on FPP3 best practices\n  MAE <- function(pred, actual) {\n    mean(abs(pred - actual), na.rm = TRUE)\n  }\n\n  RMSE <- function(pred, actual) {\n    sqrt(mean((pred - actual)^2, na.rm = TRUE))\n  }\n\n  MAPE <- function(pred, actual) {\n    mean(abs((actual - pred)/actual) * 100, na.rm = TRUE)\n  }\n\n  # Add Mean Absolute Scaled Error (MASE) - better for comparing across series\n  MASE <- function(pred, actual, train) {\n    # Scale errors by MAE of seasonal naive method on training data\n    if(length(train) <= 12) return(NA) # Need at least 13 observations\n    # Compute naive seasonal forecast errors on training data\n    naive_errors <- abs(diff(train, lag = 12))\n    # Scale forecast errors by mean of naive errors\n    mean(abs(pred - actual), na.rm = TRUE) / mean(naive_errors, na.rm = TRUE)\n  }\n\n  R2 <- function(pred, actual) {\n  1 - sum((actual - pred)^2, na.rm = TRUE) / sum((actual - mean(actual, na.rm = TRUE))^2, na.rm = TRUE)\n  }\n\n  # Innovation R^2 (Nash-Sutcliffe Efficiency)\n  Innovation_R2 <- function(pred, actual) {\n    # Skip if not enough data\n    if(length(actual) < 2) return(NA)\n    \n    # Create naive forecast (previous value)\n    naive <- c(NA, head(actual, -1))\n    \n    # Remove first point where we can't calculate error\n    pred <- pred[-1]\n    actual <- actual[-1]\n    naive <- naive[-1]\n    \n    # Calculate Innovation R^2\n    1 - sum((actual - pred)^2, na.rm=TRUE) / sum((actual - naive)^2, na.rm=TRUE)\n  }\n\n  # Calculate metrics for all models with expanded metrics\n  metrics <- data.frame(\n    Model = c(\"Linear Regression\", \"Auto ARIMA\", \"Prophet\", \"Neural Prophet\"),\n    MAE = c(\n      MAE(lm_preds, test_actuals),\n      MAE(arima_preds, test_actuals),\n      MAE(prophet_preds, test_actuals),\n      if(!is.null(np_preds)) MAE(np_preds, test_actuals) else NA\n    ),\n    RMSE = c(\n      RMSE(lm_preds, test_actuals),\n      RMSE(arima_preds, test_actuals),\n      RMSE(prophet_preds, test_actuals),\n      if(!is.null(np_preds)) RMSE(np_preds, test_actuals) else NA\n    ),\n    MAPE = c(\n      MAPE(lm_preds, test_actuals),\n      MAPE(arima_preds, test_actuals),\n      MAPE(prophet_preds, test_actuals),\n      if(!is.null(np_preds)) MAPE(np_preds, test_actuals) else NA\n    ),\n    MASE = c(\n      MASE(lm_preds, test_actuals, train_data$Average.Price),\n      MASE(arima_preds, test_actuals, train_data$Average.Price),\n      MASE(prophet_preds, test_actuals, train_data$Average.Price),\n      if(!is.null(np_preds)) MASE(np_preds, test_actuals, train_data$Average.Price) else NA\n    ),\n    R2 = c(\n      R2(lm_preds, test_actuals),\n      R2(arima_preds, test_actuals),\n      R2(prophet_preds, test_actuals),\n      if(!is.null(np_preds)) R2(np_preds, test_actuals) else NA\n    ),\n    Innovation_R2 = c(\n      Innovation_R2(lm_preds, test_actuals),\n      Innovation_R2(arima_preds, test_actuals),\n      Innovation_R2(prophet_preds, test_actuals),\n      if(!is.null(np_preds)) Innovation_R2(np_preds, test_actuals) else NA\n    )\n    \n  )\n    \n\n  # --- CREATE FORECAST COMPARISON PLOT ---\n    \n  # Create a combined dataframe for plotting\n  plot_data <- rbind(\n    # Historical data\n    data.frame(\n      Date = data$date,\n      Value = data$Average.Price,\n      Method = \"Historical\"\n    ),\n    \n    # Forecast data - Linear Regression (ensure this is included)\n    data.frame(\n      Date = test_dates,\n      Value = lm_preds,\n      Method = \"Linear Regression\"\n    ),\n    \n    # Forecast data - Auto ARIMA\n    data.frame(\n      Date = test_dates,\n      Value = arima_preds,\n      Method = \"Auto ARIMA\"\n    ),\n    \n    # Forecast data - Prophet\n    data.frame(\n      Date = test_dates,\n      Value = prophet_preds,\n      Method = \"Prophet\"\n    )\n  )\n\n  # Add Neural Prophet predictions if available\n  if(!is.null(np_preds) && length(np_preds) == length(test_dates)) {\n    np_df <- data.frame(\n      Date = test_dates,\n      Value = np_preds,\n      Method = \"Neural Prophet\"\n    )\n    plot_data <- rbind(plot_data, np_df)\n  }\n  \n  # Set up colors that match FPP3 style\n  plot_colors <- c(\n    \"Historical\" = \"black\",\n    \"Linear Regression\" = \"red\",\n    \"Auto ARIMA\" = \"orange\",\n    \"Prophet\" = \"green3\",\n    \"Neural Prophet\" = \"blue\"\n  )\n  \n  # Create the improved plot\n  main_plot <- ggplot() +\n    # Add all lines using the combined data frame\n    geom_line(data = plot_data, \n              aes(x = Date, y = Value, color = Method, \n                  size = Method, linetype = Method), \n              alpha = 0.9) +\n    \n    # Training/Test split vertical line\n    geom_vline(xintercept = as.numeric(as.Date(\"2021-06-01\")), \n              linetype = \"dashed\", color = \"darkgray\") +\n    \n    # Add text annotation for train/test split\n    annotate(\"text\", x = as.Date(\"2021-06-01\"), y = max(data$Average.Price)*0.8, \n            label = \"Train/Test Split\", angle = 90, hjust = -0.1, size = 3) +\n    \n    # Set up proper colors, sizes and line types\n    scale_color_manual(values = plot_colors) +\n    scale_size_manual(values = c(\n      \"Historical\" = 0.8,\n      \"Linear Regression\" = 0.7,\n      \"Auto ARIMA\" = 0.7,\n      \"Prophet\" = 0.7,\n      \"Neural Prophet\" = 0.7\n    )) +\n    scale_linetype_manual(values = c(\n      \"Historical\" = \"solid\",\n      \"Linear Regression\" = \"solid\", \n      \"Auto ARIMA\" = \"solid\",\n      \"Prophet\" = \"solid\",\n      \"Neural Prophet\" = \"solid\"\n    )) +\n    \n    # Enhanced styling to match FPP3\n    labs(title = paste(item_name, \"Price Forecast\"),\n        subtitle = \"Training: Jan 2018-Jun 2021, Testing: Jul 2021-Dec 2022\",\n        x = NULL, \n        y = \"Price (AUD)\") +\n    theme_minimal(base_size = 11) +\n    theme(\n      plot.title = element_text(size = 12, face = \"bold\"),\n      plot.subtitle = element_text(size = 10),\n      axis.title.y = element_text(size = 10),\n      legend.position = \"bottom\",\n      legend.title = element_blank(),\n      legend.box.margin = margin(t = -10),\n      panel.grid.minor = element_blank(),\n      panel.grid.major.x = element_line(linewidth = 0.3, color = \"gray90\"),\n      panel.grid.major.y = element_line(linewidth = 0.3, color = \"gray90\"),\n      plot.margin = margin(t = 10, r = 10, b = 10, l = 10)\n    )\n  \n  print(main_plot)\n  \n  return(list(\n    plot = main_plot,\n    metrics = metrics,\n    test_dates = test_dates,\n    test_actuals = test_actuals,\n    lm_preds = lm_preds,\n    arima_preds = arima_preds,\n    prophet_preds = prophet_preds,\n    np_preds = np_preds\n  ))\n}\n\n\ncreate_simple_metrics_table <- function(all_metrics) {\n\n  if(nrow(all_metrics) == 0) {\n    cat(\"No metrics available. All models failed.\\n\")\n    return(list(tables = list(), combined = data.frame()))\n  }\n  # Create a simple table for each food item\n  tables <- list()\n  \n  for (item_name in unique(all_metrics$Item)) {\n    item_metrics <- all_metrics %>%\n      filter(Item == item_name) %>%\n      select(Model, MAE, RMSE, MAPE, R2, Innovation_R2)\n    \n    # Round values for display\n    item_metrics_rounded <- item_metrics %>%\n      mutate(across(c(MAE, RMSE, MAPE, R2, Innovation_R2), ~round(., 4)))\n    \n    # Create simple table output\n    cat(\"\\nModel Performance Metrics for\", item_name, \"\\n\")\n    print(item_metrics_rounded)\n    \n    # Store the table for potential later use\n    tables[[item_name]] <- item_metrics_rounded\n  }\n\n  \n  # Create a simple combined metrics table\n  combined_metrics <- all_metrics %>%\n    group_by(Model) %>%\n    summarise(\n      Avg_MAE = mean(MAE, na.rm = TRUE),\n      Avg_RMSE = mean(RMSE, na.rm = TRUE),\n      Avg_MAPE = mean(MAPE, na.rm = TRUE),\n      Avg_R2 = mean(R2, na.rm = TRUE),\n      Avg_Innovation_R2 = mean(Innovation_R2, na.rm = TRUE)\n    ) %>%\n    ungroup() %>%\n    mutate(across(c(Avg_MAE, Avg_RMSE, Avg_MAPE, Avg_R2), ~round(., 4)))\n  \n  cat(\"\\nAverage Model Performance Across All Food Items\\n\")\n  print(combined_metrics)\n  \n  return(list(tables = tables, combined = combined_metrics))\n}","metadata":{"execution":{"iopub.status.busy":"2025-07-12T14:12:41.324550Z","iopub.execute_input":"2025-07-12T14:12:41.325930Z","iopub.status.idle":"2025-07-12T14:12:41.348297Z","shell.execute_reply":"2025-07-12T14:12:41.346887Z"},"papermill":{"duration":0.050218,"end_time":"2025-06-26T01:44:00.542169","exception":false,"start_time":"2025-06-26T01:44:00.491951","status":"completed"},"tags":[],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# --- 3. RUN COMPREHENSIVE ANALYSIS ---\ncat(\"=== ESSENTIAL FOOD PRICE FORECASTING ANALYSIS ===\\n\")\ncat(\"Training period: Jan 2018 - Jun 2021\\n\")\ncat(\"Testing period: Jul 2021 - Dec 2022\\n\")\n\n# Install required packages if not already installed\nif (!require(\"knitr\")) install.packages(\"knitr\")\n\n# Initialize results storage\nall_results <- list()\nall_metrics <- data.frame()\n\n# Analyze each food item\nfor(item in names(food_items)) {\n  # Add robust error handling\n  tryCatch({\n    result <- comprehensive_forecast_analysis(food_items[[item]], item)\n    all_results[[item]] <- result\n    \n    # Add item name to metrics\n    result$metrics$Item <- item\n    all_metrics <- rbind(all_metrics, result$metrics)\n  }, error = function(e) {\n    cat(\"Error analyzing\", item, \":\", e$message, \"\\n\")\n    \n    # ADDED: Create simpler fallback analysis\n    cat(\"Attempting simpler analysis for\", item, \"...\\n\")\n    tryCatch({\n      # Get data splits\n      train_data <- food_items[[item]] %>% \n        filter(date >= as.Date('2018-01-01') & date <= as.Date('2021-06-01'))\n      test_data <- food_items[[item]] %>% \n        filter(date >= as.Date('2021-07-01') & date <= as.Date('2022-12-01'))\n      test_actuals <- test_data$Average.Price\n      \n      # Simple linear model\n      lm_simple <- lm(Average.Price ~ as.numeric(date), data = train_data)\n      lm_preds <- predict(lm_simple, newdata = test_data)\n      \n      # Simple ARIMA\n      ts_train <- ts(train_data$Average.Price, frequency = 12)\n      arima_model <- auto.arima(ts_train)\n      arima_preds <- forecast(arima_model, h = length(test_actuals))$mean\n      \n      # Create fallback metrics\n      fallback_metrics <- data.frame(\n        Model = c(\"Linear Regression\", \"Auto ARIMA\"),\n        MAE = c(mean(abs(lm_preds - test_actuals)), mean(abs(arima_preds - test_actuals))),\n        RMSE = c(sqrt(mean((lm_preds - test_actuals)^2)), sqrt(mean((arima_preds - test_actuals)^2))),\n        MAPE = c(mean(abs((test_actuals - lm_preds)/test_actuals) * 100), \n                mean(abs((test_actuals - arima_preds)/test_actuals) * 100)),\n        R2 = c(1 - sum((test_actuals - lm_preds)^2) / sum((test_actuals - mean(test_actuals))^2),\n              1 - sum((test_actuals - arima_preds)^2) / sum((test_actuals - mean(test_actuals))^2)),\n        Item = item\n      )\n      \n      all_metrics <- rbind(all_metrics, fallback_metrics)\n      cat(\"Added fallback metrics for\", item, \"\\n\")\n    }, error = function(e2) {\n      cat(\"Fallback analysis also failed for\", item, \":\", e2$message, \"\\n\")\n    })\n  })\n}\n\n# --- SHOW COMBINED VISUALIZATION FIRST ---\n# Move this section before metrics tables\nif(length(all_results) == 4 && all(sapply(all_results, function(x) !is.null(x$plot)))) {\n  cat(\"\\n=== COMBINED VISUALIZATION OF ALL FOOD ITEMS ===\\n\")\n  \n  # Add more spacing and reduce text size to avoid overlapping\n  # Extract individual plots but remove their legends and simplify titles\n  bread_plot <- all_results$Bread$plot + \n    theme(\n      legend.position = \"none\",\n      plot.title = element_text(size = 10, face = \"bold\"),\n      plot.subtitle = element_blank(),\n      plot.margin = margin(t = 15, r = 15, b = 15, l = 15)\n    ) +\n    labs(title = \"Bread\", subtitle = NULL)\n  \n  milk_plot <- all_results$Milk$plot + \n    theme(\n      legend.position = \"none\",\n      plot.title = element_text(size = 10, face = \"bold\"),\n      plot.subtitle = element_blank(),\n      plot.margin = margin(t = 15, r = 15, b = 15, l = 15)\n    ) +\n    labs(title = \"Milk\", subtitle = NULL)\n  \n  eggs_plot <- all_results$Eggs$plot + \n    theme(\n      legend.position = \"none\",\n      plot.title = element_text(size = 10, face = \"bold\"),\n      plot.subtitle = element_blank(),\n      plot.margin = margin(t = 15, r = 15, b = 15, l = 15)\n    ) +\n    labs(title = \"Eggs\", subtitle = NULL)\n  \n  potatoes_plot <- all_results$Potatoes$plot + \n    theme(\n      legend.position = \"none\",\n      plot.title = element_text(size = 10, face = \"bold\"),\n      plot.subtitle = element_blank(),\n      plot.margin = margin(t = 15, r = 15, b = 15, l = 15)\n    ) +\n    labs(title = \"Potatoes\", subtitle = NULL)\n  \n  # Create a simplified legend\n  legend <- get_legend(\n    all_results$Bread$plot + \n      guides(color = guide_legend(nrow = 1)) +\n      theme(legend.position = \"bottom\")\n  )\n  \n  # Use layout_matrix to add more space between plots\n  combined_plot <- grid.arrange(\n    arrangeGrob(bread_plot, top = textGrob(\"\")),\n    arrangeGrob(milk_plot, top = textGrob(\"\")),\n    arrangeGrob(eggs_plot, top = textGrob(\"\")),\n    arrangeGrob(potatoes_plot, top = textGrob(\"\")),\n    ncol = 2,\n    nrow = 2,\n    bottom = legend,\n    top = textGrob(\"Essential Food Price Forecasting for Australia\",\n                  gp = gpar(fontsize = 12, fontface = \"bold\")),\n    padding = unit(2, \"line\")  # Add padding between plots\n  )\n  \n  print(combined_plot)\n}\n","metadata":{"execution":{"iopub.status.busy":"2025-07-12T14:12:41.350744Z","iopub.execute_input":"2025-07-12T14:12:41.351943Z","iopub.status.idle":"2025-07-12T14:12:44.127125Z","shell.execute_reply":"2025-07-12T14:12:44.123717Z"},"papermill":{"duration":205.694736,"end_time":"2025-06-26T01:47:26.239767","exception":false,"start_time":"2025-06-26T01:44:00.545031","status":"completed"},"tags":[],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[{"name":"stdout","text":"=== ESSENTIAL FOOD PRICE FORECASTING ANALYSIS ===\nTraining period: Jan 2018 - Jun 2021\nTesting period: Jul 2021 - Dec 2022\n\n ============================================================ \nANALYZING: Bread \n============================================================ \nError analyzing Bread : object 'test_features' not found \nAttempting simpler analysis for Bread ...\nAdded fallback metrics for Bread \n\n ============================================================ \nANALYZING: Milk \n============================================================ \nError analyzing Milk : object 'test_features' not found \nAttempting simpler analysis for Milk ...\nAdded fallback metrics for Milk \n\n ============================================================ \nANALYZING: Eggs \n============================================================ \nError analyzing Eggs : object 'test_features' not found \nAttempting simpler analysis for Eggs ...\nAdded fallback metrics for Eggs \n\n ============================================================ \nANALYZING: Potatoes \n============================================================ \nError analyzing Potatoes : object 'test_features' not found \nAttempting simpler analysis for Potatoes ...\nAdded fallback metrics for Potatoes \n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"\n# --- NOW SHOW METRICS TABLES AFTER VISUALIZATIONS ---\n# Ensure create_simple_metrics_table can handle empty data\nif(nrow(all_metrics) == 0) {\n  cat(\"No analyses succeeded. Cannot create metric tables.\\n\")\n} else {\n  cat(\"\\n=== MODEL PERFORMANCE METRICS ===\\n\")\n  # Create simple metrics tables\n  metrics_tables <- create_simple_metrics_table(all_metrics)\n  \n  # Display individual metric comparisons\n  cat(\"\\n=== METRIC COMPARISON ACROSS MODELS ===\\n\")\n  \n  # MAE comparison\n  cat(\"\\nMean Absolute Error (MAE) by Model and Food Item:\\n\")\n  mae_comparison <- all_metrics %>%\n    select(Model, Item, MAE) %>%\n    pivot_wider(names_from = Item, values_from = MAE) %>%\n    mutate(across(-Model, ~round(., 4)))\n  print(mae_comparison)\n  \n  # RMSE comparison\n  cat(\"\\nRoot Mean Square Error (RMSE) by Model and Food Item:\\n\")\n  rmse_comparison <- all_metrics %>%\n    select(Model, Item, RMSE) %>%\n    pivot_wider(names_from = Item, values_from = RMSE) %>%\n    mutate(across(-Model, ~round(., 4)))\n  print(rmse_comparison)\n  \n  # MAPE comparison\n  cat(\"\\nMean Absolute Percentage Error (MAPE) by Model and Food Item:\\n\")\n  mape_comparison <- all_metrics %>%\n    select(Model, Item, MAPE) %>%\n    pivot_wider(names_from = Item, values_from = MAPE) %>%\n    mutate(across(-Model, ~round(., 4)))\n  print(mape_comparison)\n  \n  # R2 comparison\n  cat(\"\\nR-squared (R2) by Model and Food Item:\\n\")\n  r2_comparison <- all_metrics %>%\n    select(Model, Item, R2) %>%\n    pivot_wider(names_from = Item, values_from = R2) %>%\n    mutate(across(-Model, ~round(., 4)))\n  print(r2_comparison)\n  \n  # Innovation R2 comparison\n  cat(\"\\nInnovation R-squared (Innovation_R2) by Model and Food Item:\\n\")\n  innr2_comparison <- all_metrics %>%\n    select(Model, Item, Innovation_R2) %>%\n    pivot_wider(names_from = Item, values_from = Innovation_R2) %>%\n    mutate(across(-Model, ~round(., 4)))\n  print(innr2_comparison)\n}","metadata":{"execution":{"iopub.status.busy":"2025-07-12T14:12:44.132430Z","iopub.execute_input":"2025-07-12T14:12:44.135276Z","iopub.status.idle":"2025-07-12T14:12:44.161898Z","shell.execute_reply":"2025-07-12T14:12:44.158506Z"},"papermill":{"duration":0.271685,"end_time":"2025-06-26T01:47:26.527168","exception":false,"start_time":"2025-06-26T01:47:26.255483","status":"completed"},"tags":[],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[{"name":"stdout","text":"No analyses succeeded. Cannot create metric tables.\n","output_type":"stream"}],"execution_count":24}]}